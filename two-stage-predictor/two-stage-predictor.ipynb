{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"regression_activation\" (type Lambda).\n\nDimensions must be equal, but are 6 and 2 for '{{node regression_activation/mul}} = Mul[T=DT_FLOAT](Placeholder, Placeholder_1)' with input shapes: [?,6], [?,2].\n\nCall arguments received by layer \"regression_activation\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 6), dtype=float32)', 'tf.Tensor(shape=(None, 2), dtype=float32)']\n  • mask=None\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\thiru\\Desktop\\Aashritha project\\python_code\\CascadedClassificationAndRegression.ipynb Cell 1\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m regression_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mconcatenate([regression_input_layer, classification_output])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Define a lambda layer that conditionally activates the regression model based on the output of the classification model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m regression_activation \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLambda(\u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m x[\u001b[39m1\u001b[39;49m], name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mregression_activation\u001b[39;49m\u001b[39m'\u001b[39;49m)([regression_input, classification_output])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Connect the regression model to the output of the classification model, using the regression_activation layer to conditionally activate it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m regression_output \u001b[39m=\u001b[39m regression_activation \u001b[39m*\u001b[39m regression_model(regression_input)\n",
      "File \u001b[1;32mc:\\Users\\thiru\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "\u001b[1;32mc:\\Users\\thiru\\Desktop\\Aashritha project\\python_code\\CascadedClassificationAndRegression.ipynb Cell 1\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m regression_input \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mconcatenate([regression_input_layer, classification_output])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# Define a lambda layer that conditionally activates the regression model based on the output of the classification model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m regression_activation \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLambda(\u001b[39mlambda\u001b[39;00m x: x[\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m x[\u001b[39m1\u001b[39;49m], name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mregression_activation\u001b[39m\u001b[39m'\u001b[39m)([regression_input, classification_output])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Connect the regression model to the output of the classification model, using the regression_activation layer to conditionally activate it\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thiru/Desktop/Aashritha%20project/python_code/CascadedClassificationAndRegression.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m regression_output \u001b[39m=\u001b[39m regression_activation \u001b[39m*\u001b[39m regression_model(regression_input)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"regression_activation\" (type Lambda).\n\nDimensions must be equal, but are 6 and 2 for '{{node regression_activation/mul}} = Mul[T=DT_FLOAT](Placeholder, Placeholder_1)' with input shapes: [?,6], [?,2].\n\nCall arguments received by layer \"regression_activation\" (type Lambda):\n  • inputs=['tf.Tensor(shape=(None, 6), dtype=float32)', 'tf.Tensor(shape=(None, 2), dtype=float32)']\n  • mask=None\n  • training=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the classification model\n",
    "classification_model = tf.keras.models.load_model('TTC_classification_model.h5')\n",
    "\n",
    "# Load the regression model\n",
    "regression_model = tf.keras.models.load_model('TTC_regression_model.h5')\n",
    "\n",
    "# Define the input shape for the classification model\n",
    "classification_input_shape = classification_model.layers[0].input_shape\n",
    "\n",
    "# Define the input layer for the regression model\n",
    "regression_input_layer = tf.keras.layers.Input(shape=classification_input_shape[1:])\n",
    "\n",
    "# Connect the output of the classification model to the input of the regression model\n",
    "classification_output = classification_model(regression_input_layer)\n",
    "regression_input = tf.keras.layers.concatenate([regression_input_layer, classification_output])\n",
    "\n",
    "# Define a lambda layer that conditionally activates the regression model based on the output of the classification model\n",
    "regression_activation = tf.keras.layers.Lambda(lambda x: x[0] * x[1], name='regression_activation')([regression_input, classification_output])\n",
    "\n",
    "# Connect the regression model to the output of the classification model, using the regression_activation layer to conditionally activate it\n",
    "regression_output = regression_activation * regression_model(regression_input)\n",
    "\n",
    "# Define the combined model that includes both the classification and regression models\n",
    "combined_model = tf.keras.models.Model(inputs=regression_input_layer, outputs=regression_output)\n",
    "\n",
    "# Compile the combined model with the desired loss function and optimizer\n",
    "combined_model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('D:\\\\NewFinalDatasetsForNeuralNetwork\\\\crash_noncrash_combined_csv_09_03_2023__13_24.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.displot(dataset['TTC'], kde = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting TTC from the other columns\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 80-20 Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is only used for plotting the training dataset in the below cell, alongwith the column names\n",
    "joined_train_dataset = X_train\n",
    "train_dataset = pd.DataFrame(joined_train_dataset, columns = ['NORMALIZED PEDESTRIAN POSITION X', 'NORMALIZED PEDESTRIAN POSITION Y', 'NORMALIZED PEDESTRIAN DIRECTION', 'NORMALIZED PEDESTRIAN SPEED'])\n",
    "train_dataset.loc[:,'TTC'] = y_train\n",
    "#print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "# Defining first layer of the neural network, which normalizes the input data on the fly\n",
    "normalizer_layer = keras.layers.Normalization(axis=-1)\n",
    "normalizer_layer = layers.Normalization(input_shape=[4,], axis=None)\n",
    "# Adapting normalizer layer to the input train data shape\n",
    "normalizer_layer.adapt(np.array(X_train))\n",
    "\n",
    "# Defines the model and compilation\n",
    "def build_and_compile_model(normalizer_layer):\n",
    "  nn_model = keras.Sequential([\n",
    "      normalizer_layer,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(128, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  nn_model.compile(loss='mean_squared_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=['mse'])\n",
    "  return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the neural network model and compiling it using the normalization layer adapted to the shape of our input training dataset\n",
    "dnn_model = build_and_compile_model(normalizer_layer)\n",
    "dnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report for training data for non linear model\n",
    "#%%time\n",
    "history = dnn_model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "# Calculate validation results on 20% of the training data.\n",
    "    validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------------------------------Regression Model----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a new column 'TTC Category' and bin values based on their range\n",
    "bins = [-1, 7, np.inf]\n",
    "labels = ['crash', 'no_crash']\n",
    "dataset['SCENARIO TYPE'] = pd.cut(dataset['TTC'], bins=bins, labels=labels)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Select column to one hot encode\n",
    "col_to_encode = 'SCENARIO TYPE'\n",
    "\n",
    "# Perform one hot encoding\n",
    "one_hot_encoded = pd.get_dummies(dataset[col_to_encode], prefix=col_to_encode)\n",
    "\n",
    "# Append one hot encoded columns to original dataset\n",
    "dataset = pd.concat([dataset, one_hot_encoded], axis=1)\n",
    "\n",
    "# Drop original column that was one hot encoded\n",
    "dataset = dataset.drop(col_to_encode, axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset['SCENARIO TYPE'] = data_transformed\n",
    "dataset = dataset.drop('TTC', axis=1)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset into features and labels\n",
    "X = dataset.drop(columns=[\"SCENARIO TYPE_crash\", \"SCENARIO TYPE_no_crash\"]).values\n",
    "#X = dataset.drop(columns=[\"SCENARIO TYPE\"]).values\n",
    "#y = dataset[[\"SCENARIO TYPE\"]].values\n",
    "y = dataset[[\"SCENARIO TYPE_crash\", \"SCENARIO TYPE_no_crash\"]].values\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "# Defining first layer of the neural network, which normalizes the input data on the fly\n",
    "normalizer_layer = keras.layers.Normalization(axis=-1)\n",
    "normalizer_layer = keras.layers.Normalization(input_shape=[4,], axis=None)\n",
    "# Adapting normalizer layer to the input train data shape\n",
    "normalizer_layer.adapt(np.array(X_train))\n",
    "\n",
    "# Defines the model and compilation\n",
    "def build_and_compile_model(normalizer_layer):\n",
    "  nn_model = keras.Sequential([\n",
    "      normalizer_layer,\n",
    "      keras.layers.Dense(128, activation='relu', kernel_initializer='he_uniform'),\n",
    "      keras.layers.Dense(64, activation='sigmoid'),\n",
    "      keras.layers.Dense(32, activation='relu'),\n",
    "      keras.layers.Dense(y.shape[1], activation=\"softmax\")\n",
    "  ])\n",
    "\n",
    "  nn_model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=[\"categorical_accuracy\"])\n",
    "  return nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_model = build_and_compile_model(normalizer_layer)\n",
    "# Train the model\n",
    "history = dnn_model.fit(X_train, y_train, epochs=300, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = dnn_model.evaluate(X_test, y_test)\n",
    "print(\"Test set accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
